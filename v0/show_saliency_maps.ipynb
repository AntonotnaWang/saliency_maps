{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# show saliency maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from func.loadimg import get_example_pic_and_preprocess, generate_example_list, get_file_path\n",
    "from func.utils import get_pretrained_model, preprocess_image, convert_to_grayscale, format_np_output, save_image, save_gradient_images, get_positive_negative\n",
    "from func.saliency_maps import GuidedBackprop, VanillaBackprop, SmoothGrad, GradCAM, GuidedGradCAM, IntegratedGradients, GradientxInput, DeepLIFT\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "sample_data_filepath = os.path.abspath(os.path.join(get_file_path(), \"..\"))+\"/../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some funcitons for illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a unified way to conduct saliency map methods\n",
    "def conduct_saliency_map_method(METHOD, processed_img_tensor, target_class_index, pretrained_model, which_layer_to_hook=0):\n",
    "    saliency_map_method = METHOD(pretrained_model, which_layer_to_hook)\n",
    "    saliency_map, feature_map = saliency_map_method.generate_explanation(processed_img_tensor, target_class_index)\n",
    "    return saliency_map, feature_map, saliency_map_method\n",
    "\n",
    "# used to show saliency maps\n",
    "def process_results_for_one_method(saliency_map, feature_map):\n",
    "    \n",
    "    grayscale_saliency_map = convert_to_grayscale(saliency_map)[0]\n",
    "    grayscale_feature_map = convert_to_grayscale(feature_map)[0]\n",
    "    \n",
    "    pos_saliency_map, neg_saliency_map = get_positive_negative(saliency_map)\n",
    "    blank = np.zeros(pos_saliency_map.shape)\n",
    "    pos_neg_saliency_map = np.concatenate((pos_saliency_map,blank,neg_saliency_map),axis=0)\n",
    "    pos_neg_saliency_map = pos_neg_saliency_map.transpose(1,2,0)\n",
    "    \n",
    "    return grayscale_saliency_map, grayscale_feature_map, pos_neg_saliency_map\n",
    "\n",
    "def show_results_for_one_method(original_image, saliency_map, feature_map, which_layer_to_hook, color_map = \"gray\"):\n",
    "    \n",
    "    grayscale_saliency_map, grayscale_feature_map, pos_neg_saliency_map = process_results_for_one_method(saliency_map, feature_map)\n",
    "    \n",
    "    plt.figure(figsize = (15,20))\n",
    "    \n",
    "    if which_layer_to_hook == 0:\n",
    "        ax1 = plt.subplot(1,3,1)\n",
    "        ax1.set_title(\"input image\")\n",
    "        ax1.imshow(original_image)\n",
    "        \n",
    "        ax2 = plt.subplot(1,3,2)\n",
    "        ax2.set_title(\"grayscale saliency map\")\n",
    "        ax2.imshow(grayscale_saliency_map, cmap=plt.get_cmap(color_map))\n",
    "        \n",
    "        ax3 = plt.subplot(1,3,3)\n",
    "        ax3.set_title(\"saliency map (pos: red, neg: blue)\")\n",
    "        ax3.imshow(pos_neg_saliency_map)\n",
    "        \n",
    "        plt.show()\n",
    "    else:\n",
    "        ax1 = plt.subplot(1,4,1)\n",
    "        ax1.set_title(\"input image\")\n",
    "        ax1.imshow(original_image)\n",
    "        \n",
    "        ax2 = plt.subplot(1,4,2)\n",
    "        ax2.set_title(\"grayscale saliency map\")\n",
    "        ax2.imshow(grayscale_saliency_map, cmap=plt.get_cmap(color_map))\n",
    "        \n",
    "        ax3 = plt.subplot(1,4,3)\n",
    "        ax3.set_title(\"saliency map (pos: red, neg: blue)\")\n",
    "        ax3.imshow(pos_neg_saliency_map)\n",
    "        \n",
    "        ax4 = plt.subplot(1,4,4)\n",
    "        ax4.set_title(\"grayscale feature map\")\n",
    "        ax4.imshow(grayscale_feature_map, cmap=plt.get_cmap(color_map))\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# see image list and their corresponding correct prediction index\n",
    "# label_index_dict_filepath: a json file showing the match of Imagenet index and CNN correct prediction index\n",
    "# pic_filepath: filepath of the filefolder of images\n",
    "\n",
    "image_list = generate_example_list(label_index_dict_filepath = sample_data_filepath+\"/imagenet_label_index.json\",\n",
    "                                   pic_filepath = sample_data_filepath+\"/images\")\n",
    "for idx, image in enumerate(image_list):\n",
    "    print(\"example index: \"+str(idx)+\";    image name: \"+str(image[0])+\";    correct prediction index: \"+str(image[1])+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conduct saliency map methods one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load one img\n",
    "# example_index: you can provide the index of the image, or assign it with None (the program will pick one random picture)\n",
    "# label_index_dict_filepath: a json file showing the match of Imagenet index and CNN correct prediction index\n",
    "# pic_filepath: filepath of the filefolder of images\n",
    "(original_image, resized_image, processed_img_tensor, target_class_index, file_name_to_export) = \\\n",
    "get_example_pic_and_preprocess(example_index=None,\n",
    "                               label_index_dict_filepath = sample_data_filepath+\"/imagenet_label_index.json\",\n",
    "                               pic_filepath = sample_data_filepath+\"/images\")\n",
    "\n",
    "# decision which layer to want to observe\n",
    "# 0 means saliency map the the input image, which_layer_to_hook>0 means the saliency map of which_layer_to_hook th intermediate layer\n",
    "which_layer_to_hook = 0\n",
    "\n",
    "# decide which pretrained CNN to use\n",
    "model_name = \"alexnet\"\n",
    "\n",
    "# Attention: the pretrained model should be loaded every time using a saliency map method\n",
    "\n",
    "# GuidedBackprop\n",
    "# load pre-trained model\n",
    "pretrained_model = get_pretrained_model(model_name)\n",
    "saliency_map, feature_map, _ = conduct_saliency_map_method(GuidedBackprop, processed_img_tensor, target_class_index,\n",
    "                                                        pretrained_model, which_layer_to_hook=which_layer_to_hook)\n",
    "show_results_for_one_method(resized_image, saliency_map, feature_map, which_layer_to_hook=which_layer_to_hook)\n",
    "\n",
    "# VanillaBackprop\n",
    "# load pre-trained model\n",
    "pretrained_model = get_pretrained_model(model_name)\n",
    "saliency_map, feature_map, _= conduct_saliency_map_method(VanillaBackprop, processed_img_tensor, target_class_index,\n",
    "                                                        pretrained_model, which_layer_to_hook=which_layer_to_hook)\n",
    "show_results_for_one_method(resized_image, saliency_map, feature_map, which_layer_to_hook=which_layer_to_hook)\n",
    "\n",
    "# SmoothGrad\n",
    "# load pre-trained model\n",
    "pretrained_model = get_pretrained_model(model_name)\n",
    "saliency_map, feature_map, _ = conduct_saliency_map_method(SmoothGrad, processed_img_tensor, target_class_index,\n",
    "                                                        pretrained_model, which_layer_to_hook=which_layer_to_hook)\n",
    "show_results_for_one_method(resized_image, saliency_map, feature_map, which_layer_to_hook=which_layer_to_hook)\n",
    "\n",
    "# GradCAM\n",
    "# load pre-trained model\n",
    "pretrained_model = get_pretrained_model(model_name)\n",
    "saliency_map, feature_map, _ = conduct_saliency_map_method(GradCAM, processed_img_tensor, target_class_index,\n",
    "                                                        pretrained_model, which_layer_to_hook=11)\n",
    "show_results_for_one_method(resized_image, saliency_map, feature_map, which_layer_to_hook=11)\n",
    "\n",
    "# IntegratedGradients\n",
    "# load pre-trained model\n",
    "pretrained_model = get_pretrained_model(model_name)\n",
    "saliency_map, feature_map, _ = conduct_saliency_map_method(IntegratedGradients, processed_img_tensor, target_class_index,\n",
    "                                                        pretrained_model, which_layer_to_hook=which_layer_to_hook)\n",
    "show_results_for_one_method(resized_image, saliency_map, feature_map, which_layer_to_hook=which_layer_to_hook)\n",
    "\n",
    "# GradientxInput\n",
    "# load pre-trained model\n",
    "pretrained_model = get_pretrained_model(model_name)\n",
    "saliency_map, feature_map, _ = conduct_saliency_map_method(GradientxInput, processed_img_tensor, target_class_index,\n",
    "                                                        pretrained_model, which_layer_to_hook=which_layer_to_hook)\n",
    "show_results_for_one_method(resized_image, saliency_map, feature_map, which_layer_to_hook=which_layer_to_hook)\n",
    "\n",
    "# DeepLIFT\n",
    "# load pre-trained model\n",
    "pretrained_model = get_pretrained_model(model_name)\n",
    "saliency_map, feature_map, _ = conduct_saliency_map_method(DeepLIFT, processed_img_tensor, target_class_index,\n",
    "                                                        pretrained_model, which_layer_to_hook=which_layer_to_hook)\n",
    "show_results_for_one_method(resized_image, saliency_map, feature_map, which_layer_to_hook=which_layer_to_hook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# decide which pretrained CNN to use\n",
    "model_name = \"alexnet\"\n",
    "\n",
    "# decision which layer to want to observe\n",
    "# 0 means saliency map the the input image, which_layer_to_hook>0 means the saliency map of which_layer_to_hook th intermediate layer\n",
    "which_layer_to_hook = 0\n",
    "\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "num_of_examples = 5\n",
    "num_of_saliency_methods = 6\n",
    "\n",
    "gs = gridspec.GridSpec(num_of_examples, num_of_saliency_methods+1)\n",
    "\n",
    "for i in range(num_of_examples):\n",
    "    (original_image, resized_image, processed_img_tensor, target_class_index, file_name_to_export) = \\\n",
    "    get_example_pic_and_preprocess(example_index=None,\n",
    "                                   label_index_dict_filepath = sample_data_filepath+\"/imagenet_label_index.json\",\n",
    "                                   pic_filepath = sample_data_filepath+\"/images\")\n",
    "    for j, METHOD in enumerate([\"Raw image\", VanillaBackprop, GuidedBackprop, SmoothGrad, IntegratedGradients, GradientxInput, DeepLIFT]):\n",
    "        ax = fig.add_subplot(gs[i,j])\n",
    "        if METHOD == \"Raw image\":\n",
    "            ax.imshow(resized_image)\n",
    "            ax.axis('off')\n",
    "            if i==0:\n",
    "                ax.set_title(METHOD)\n",
    "        else:\n",
    "            pretrained_model = get_pretrained_model(model_name)\n",
    "            saliency_map, feature_map, method = conduct_saliency_map_method(METHOD, processed_img_tensor, target_class_index,\n",
    "                                                                    pretrained_model, which_layer_to_hook=which_layer_to_hook)\n",
    "            grayscale_saliency_map, grayscale_feature_map, pos_neg_saliency_map = process_results_for_one_method(saliency_map, feature_map)\n",
    "            ax.imshow(grayscale_saliency_map)\n",
    "            ax.axis('off')\n",
    "            if i==0:\n",
    "                ax.set_title(method.toString())\n",
    "\n",
    "plt.savefig('saliency_maps.png',bbox_inches='tight',dpi=fig.dpi,pad_inches=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
